{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "* To demonstrates binary classification by training a model to predict if a patient should be tested for diabetes based on medical data.\n",
    "\n",
    "*Supervised* machine learning trains a model to predict a label from a set of features using data with known labels. The function can be represented as:\n",
    "\n",
    "\n",
    "> *f([x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ...]) = y*\n",
    "\n",
    "*Classification* is a supervised learning task where the model predicts the probability of each class and assigns a label. The simplest case is binary classification, where the label is either 0 or 1 (e.g., \"True\" or \"False\").\n",
    "\n"
   ],
   "id": "830f9a5c850d330d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset\n",
    "diabetes = pd.read_csv('../../generated/data/raw/diabetes.csv')\n",
    "print(diabetes.head())"
   ],
   "id": "1f0045cd983a5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The data contains diagnostic information for patients tested for diabetes.\n",
    "* The final column (**Diabetic**) is the label:\n",
    "  - **0** for patients who tested negative\n",
    "  - **1** for patients who tested positive\n",
    "* Most other columns (**Pregnancies**, **PlasmaGlucose**, **DiastolicBloodPressure**, etc.) are features used to predict the Diabetic label.\n",
    "* We'll separate features as _**X**_ and the label as _**y**_."
   ],
   "id": "7d34b3070ac4f1c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "label = 'Diabetic'\n",
    "X, y = diabetes[features].values, diabetes[label].values\n",
    "\n",
    "for n in range(0,4):\n",
    "    print(\"Patient\", str(n+1), \"\\n  Features:\",list(X[n]), \"\\n  Label:\", y[n])"
   ],
   "id": "140b561b0a87db1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### *️⃣ Compare the feature distributions for each label value.",
   "id": "245f489b745d99bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "for col in features:\n",
    "    diabetes.boxplot(column=col, by='Diabetic', figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()"
   ],
   "id": "96c1722ed72b0881",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Some features show noticeable differences in distribution for each label value.\n",
    "* **Pregnancies** and **Age** have markedly different distributions between diabetic and non-diabetic patients.\n",
    "* These features may help predict whether a patient is diabetic."
   ],
   "id": "24369e0f0733e4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Split the data\n",
    "\n",
    "To Split the dataset into two parts: one for training the model and one for testing its predictions.\n",
    "\n",
    "The aim is:\n",
    "* Evaluate the model's performance by comparing its predictions on the test set with the actual labels.\n",
    "* Assess the model's accuracy.\n",
    "\n",
    "\n",
    "The dataset contains known label values, which allows us to train a classifier to learn the relationship between features and labels.\n",
    "The `scikit-learn` package provides the `train_test_split` function to randomly divide the data.\n",
    "Typically, 70% of the data is used for training and 30% is reserved for testing."
   ],
   "id": "ff7bec4d77933d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
   ],
   "id": "dae87b8603b13a24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Train and Evaluate a Binary Classification Model\n",
    "Train our model by fitting the training features (X_train) to the training labels (y_train)\n",
    "\n",
    "* Choose an algorithm for training; here, we use Logistic Regression, a common classification method.\n",
    "* Set a regularization parameter to reduce bias and prevent overfitting.\n",
    "* Hyperparameters are settings defined outside the data, while parameters are values within the data.\n",
    "\n",
    "**Note**: Parameters for machine learning algorithms are generally referred to as *hyperparameters*. To a data scientist, *parameters* are values in the data itself - *hyperparameters* are defined externally from the data."
   ],
   "id": "9b8bf50e7cdd6ab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ],
   "id": "4d04f69150f5184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the Model with Test Data\n",
    "TO use the trained model to predict labels for the test set, then compare these predictions to the actual labels to evaluate performance.\n"
   ],
   "id": "6f199bda83bac86c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ', y_test)"
   ],
   "id": "234b5a1be91cbead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "####  Check the accuracy of the predictions\n",
    "Use the metrics provided by scikit-learn to evaluate the model.\n",
    "\n",
    "Since the arrays of labels are too long to compare manually, we use metrics to efficiently evaluate the model’s performance."
   ],
   "id": "982af87c774e4a62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ],
   "id": "8a3f01ae015c6701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Interpretation:\n",
    "An accuracy of 0.789 means the model correctly predicted about 79% of the test cases.\n",
    "\n",
    "Accuracy is shown as a decimal between 0 and 1, where 1.0 indicates perfect predictions and 0.0 means none were correct.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Here we prepared our data by splitting it into test and train datasets, and applied logistic regression - a way of applying binary labels to our data. Our model was able to predict whether patients had diabetes with what appears to be reasonable accuracy. But is this good enough? In the next notebook we will look at alternatives to accuracy that can be much more useful in machine learning."
   ],
   "id": "3be45e42a10aa851"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
